{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f065aa",
   "metadata": {},
   "source": [
    "## Webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab41346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426dd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# URL of the flipcrt search results page\n",
    "url = 'https://www.flipkart.com/home-furnishing/bed-linen-blankets/bedsheets/pr?sid=jra%2Cknw%2Cqcw&marketplace=FLIPKART&otracker=nmenu_sub_Home+%26+Furniture_0_Bedsheets&p%5B%5D=facets.rating%255B%255D%3D1%25E2%2598%2585%2B%2526%2Babove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2838f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_tab(source,tab_index):\n",
    "    link = source.get('href') #getting the URL to open in a new tab.,with html attribut href which specifies destination of link included in <a> tag\n",
    "    driver.execute_script(f'window.open(\"{link}\", \"_blank\");') #opening new tab with URL from previous step.\n",
    "\n",
    "    # Wait for the new window to open and then switch to it\n",
    "    WebDriverWait(driver, 10).until(lambda d: len(d.window_handles) > tab_index)\n",
    "    driver.switch_to.window(driver.window_handles[tab_index])\n",
    "\n",
    "    # Wait for the new tab to load its content,until HTML element with the class name 'fonts-loaded' is present on the page.\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, 'fonts-loaded'))\n",
    "    )\n",
    "\n",
    "    # Getting the HTML content of the new tab(current page)\n",
    "    new_tab_content = driver.page_source\n",
    "    soup = BeautifulSoup(new_tab_content, 'html.parser')#creating a BeautifulSoup object which can be used to parse the HTML and extract data from it\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086a03b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n  (Session info: chrome=124.0.6367.207)\nStacktrace:\n\tGetHandleVerifier [0x00007FF632411522+60802]\n\t(No symbol) [0x00007FF63238AC22]\n\t(No symbol) [0x00007FF632247CE4]\n\t(No symbol) [0x00007FF6322405B3]\n\t(No symbol) [0x00007FF6322313E4]\n\t(No symbol) [0x00007FF632232C14]\n\t(No symbol) [0x00007FF632231711]\n\t(No symbol) [0x00007FF632231049]\n\t(No symbol) [0x00007FF632230D42]\n\t(No symbol) [0x00007FF63222EBE4]\n\t(No symbol) [0x00007FF63222F22C]\n\t(No symbol) [0x00007FF63224A9F9]\n\t(No symbol) [0x00007FF6322DAB7E]\n\t(No symbol) [0x00007FF6322BAB7A]\n\t(No symbol) [0x00007FF6322DA224]\n\t(No symbol) [0x00007FF6322BA923]\n\t(No symbol) [0x00007FF632288FEC]\n\t(No symbol) [0x00007FF632289C21]\n\tGetHandleVerifier [0x00007FF6327141BD+3217949]\n\tGetHandleVerifier [0x00007FF632756157+3488183]\n\tGetHandleVerifier [0x00007FF63274F0DF+3459391]\n\tGetHandleVerifier [0x00007FF6324CB8E6+823622]\n\t(No symbol) [0x00007FF632395FBF]\n\t(No symbol) [0x00007FF632390EE4]\n\t(No symbol) [0x00007FF632391072]\n\t(No symbol) [0x00007FF6323818C4]\n\tBaseThreadInitThunk [0x00007FF82B12257D+29]\n\tRtlUserThreadStart [0x00007FF82B72AA48+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the page\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Wait for the page to fully load\u001b[39;00m\n\u001b[0;32m      9\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n  (Session info: chrome=124.0.6367.207)\nStacktrace:\n\tGetHandleVerifier [0x00007FF632411522+60802]\n\t(No symbol) [0x00007FF63238AC22]\n\t(No symbol) [0x00007FF632247CE4]\n\t(No symbol) [0x00007FF6322405B3]\n\t(No symbol) [0x00007FF6322313E4]\n\t(No symbol) [0x00007FF632232C14]\n\t(No symbol) [0x00007FF632231711]\n\t(No symbol) [0x00007FF632231049]\n\t(No symbol) [0x00007FF632230D42]\n\t(No symbol) [0x00007FF63222EBE4]\n\t(No symbol) [0x00007FF63222F22C]\n\t(No symbol) [0x00007FF63224A9F9]\n\t(No symbol) [0x00007FF6322DAB7E]\n\t(No symbol) [0x00007FF6322BAB7A]\n\t(No symbol) [0x00007FF6322DA224]\n\t(No symbol) [0x00007FF6322BA923]\n\t(No symbol) [0x00007FF632288FEC]\n\t(No symbol) [0x00007FF632289C21]\n\tGetHandleVerifier [0x00007FF6327141BD+3217949]\n\tGetHandleVerifier [0x00007FF632756157+3488183]\n\tGetHandleVerifier [0x00007FF63274F0DF+3459391]\n\tGetHandleVerifier [0x00007FF6324CB8E6+823622]\n\t(No symbol) [0x00007FF632395FBF]\n\t(No symbol) [0x00007FF632390EE4]\n\t(No symbol) [0x00007FF632391072]\n\t(No symbol) [0x00007FF6323818C4]\n\tBaseThreadInitThunk [0x00007FF82B12257D+29]\n\tRtlUserThreadStart [0x00007FF82B72AA48+40]\n"
     ]
    }
   ],
   "source": [
    "# Set up the Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "# Load the page\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to fully load\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the HTML content of the page\n",
    "html_content = driver.page_source\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find elements containing specific div information\n",
    "products = soup.find_all('div', class_='slAVV4', limit=20)\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "for product in products:\n",
    "    product_details = {} #creating an empty dictionary to store the product details for each product.\n",
    "    name = product.find('a', class_='wjcEIp')\n",
    "    name = name.text if name else \"No name available\"\n",
    "\n",
    "    # Extract the price of the product\n",
    "    price = product.find('div', class_='Nx9bqj')\n",
    "    price = price.text if price else \"No price available\"\n",
    "\n",
    "    # Extract the rating of the product\n",
    "    rating = product.find('div', class_='XQDdHH')\n",
    "    rating = rating.text if rating else \"No rating available\"\n",
    "\n",
    "\n",
    "# #Extract number of ratings and reviews\n",
    "#     num_ratings_reviews_container = product.find('span', class_='Wphh3N')\n",
    "#     if num_ratings_reviews_container:\n",
    "#         ratings_reviews_text = num_ratings_reviews_container.get_text().strip()\n",
    "        \n",
    "        \n",
    "#         # Split the text to isolate ratings and reviews\n",
    "#         ratings_text, reviews_text = ratings_reviews_text.split('&')\n",
    "        \n",
    "#         # Extract just the numbers\n",
    "#         num_ratings = ''.join(filter(str.isdigit, ratings_text))\n",
    "#         num_reviews = ''.join(filter(str.isdigit, reviews_text))\n",
    "#     else:\n",
    "#         num_ratings = \"No ratings\"\n",
    "#         num_reviews = \"No reviews\"\n",
    "\n",
    "\n",
    "# Extract number of ratings and reviews\n",
    "    num_ratings_reviews_container = product.find('span', class_='Wphh3N')\n",
    "    if num_ratings_reviews_container:\n",
    "        # Find all span elements within the container\n",
    "        span_elements = num_ratings_reviews_container.find_all('span')\n",
    "\n",
    "        # Check if there are at least 3 span elements (for ratings, '&', and reviews)\n",
    "        if len(span_elements) >= 3:\n",
    "            # Extract the text from the first and third span elements\n",
    "            ratings_text = span_elements[0].get_text().strip()\n",
    "            reviews_text = span_elements[2].get_text().strip()\n",
    "\n",
    "            # Extract just the numbers\n",
    "            num_ratings = ''.join(filter(str.isdigit, ratings_text))\n",
    "            num_reviews = ''.join(filter(str.isdigit, reviews_text))\n",
    "        else:\n",
    "            num_ratings = \"No ratings\"\n",
    "            num_reviews = \"No reviews\"\n",
    "    else:\n",
    "        num_ratings = \"No ratings\"\n",
    "        num_reviews = \"No reviews\"\n",
    "\n",
    "#--------------------------6 goshti print karacha code kadhun ahe ithun\n",
    "    \n",
    "    product_details['Product Name'] = name  #storing the extracted details in the product_details dictionary\n",
    "    product_details['Price'] = price\n",
    "    product_details['Rating'] = rating\n",
    "    product_details['Number of Ratings'] = num_ratings\n",
    "    product_details['Number of Reviews'] = num_reviews\n",
    "    \n",
    "    if num_reviews != \"No reviews\" and num_reviews != \"0\":\n",
    "        soup = switch_tab(product,1)     #If the product has reviews, it switches to the reviews tab\n",
    "\n",
    "        # Find the element with the reviews or link to reviews\n",
    "        div_element = soup.find('div', class_='col JOpGWq')\n",
    "\n",
    "        if div_element:\n",
    "            # Find all <a> tags within the div\n",
    "            all_a_tags = div_element.find_all('a') #-------------------------------------\n",
    "            # Check if there are any <a> tags\n",
    "            if len(all_a_tags) > 10:\n",
    "                # Get the last <a> tag\n",
    "                last_a_tag = all_a_tags[-1]\n",
    "\n",
    "                soup = switch_tab(last_a_tag,2) # finding the container with the reviews, extracts the summary and details of each review, and stores them in the product_details dictionary.\n",
    "                #If there are more than 10 reviews, it opens another tab to the page with the remaining reviews and extracts those as well.\n",
    "\n",
    "                reviews_container = soup.find_all('div',class_='col _2wzgFH K0kLPL')\n",
    "                review_summary_list = []\n",
    "                review_details_list = []\n",
    "                for review in reviews_container:\n",
    "                    review_summary = review.find('p',class_='_2-N8zT').text if review.find('p',class_='_2-N8zT') else \"No summary\"\n",
    "                    review_details = review.find('div',class_='t-ZTKy').text if review.find('div',class_='t-ZTKy') else \"No details\"\n",
    "                    review_summary_list.append(review_summary)\n",
    "                    review_details_list.append(review_details)\n",
    "                    # print(f\"{reviews_container.index(review)}. review_summary: {review_summary}\")\n",
    "                    # print(f\"{reviews_container.index(review)}. review_details: {review_details}\")\n",
    "                product_details['Review Summary'] = review_summary_list\n",
    "                product_details['Review Details'] = review_details_list\n",
    "                driver.close()\n",
    "            else:\n",
    "                review_summary_list = []\n",
    "                review_details_list = []\n",
    "                reviews_summary_container = soup.find_all('p',class_='_2-N8zT')\n",
    "                for reviews_summary in reviews_summary_container:\n",
    "                    reviews_summary = reviews_summary.text\n",
    "                    review_summary_list.append(reviews_summary)\n",
    "                #     # print(f\"{reviews_summary_container.index(reviews_summary)}. review_summary: {review_summary}\")\n",
    "                reviews_details_container = soup.find_all('div',class_='t-ZTKy')\n",
    "                for review_details in reviews_details_container:\n",
    "                    # print(reviews_details_container.index(review_details))\n",
    "                    review_details = review_details.text\n",
    "                    review_details_list.append(review_details)\n",
    "                    # print(f\". review_details: {review_details}\")\n",
    "                product_details['Review Summary'] = review_summary_list\n",
    "                product_details['Review Details'] = review_details_list\n",
    "\n",
    "            # print('-' *50)\n",
    "            \n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            driver.close()    #Close the reviews tab\n",
    "        driver.switch_to.window(driver.window_handles[0])\n",
    "    data.append(product_details) #It adds the product_details dictionary to the data list.\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aacad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'C:\\Users\\acer\\Desktop\\ds class\\nlp\\sentiment analysis project amazon\\scraped_data1.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad56fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
